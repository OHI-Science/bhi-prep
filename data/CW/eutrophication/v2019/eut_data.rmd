
```{r eut data preamble, echo = FALSE, include = FALSE, error = FALSE}
source(here::here("R", "data.R"))
source(here::here("R", "spatial.R"))

## root location of the raw data
dir_B <- file.path(dirname(dir_prep), "bhi-data", "BHI 2.0")
dir_rawdata <- file.path(dir_B, "Goals", "CW", "EUT")
```


### 2.1 Datasets with Sources {-}
<br/>

#### 2.1.1 Secchi Depth {-}

**ICES Secchi Depth Data**

Extraction from ICES database follows HELCOM Assessment Units – HELCOM sub-basins with coastal WFD water bodies or water types.

<!-- dataset save location BHI_share/BHI 2.0/Goals/CW/EUT/SecchiDepth_ICES -->
```{r echo = FALSE, results = "asis"}
tab <- t(data.frame(
  c("Dataset set:", "Oceanographic (per Parameter)"), 
  c("Parameter:", "secchi depth (Download)")
))
colnames(tab) <- c("Option", "Specification")
rownames(tab) <- NULL

knitr::kable(tab, caption = "Source: [ICES data portal](http://ecosystemdata.ices.dk/inventory/Index.aspx?) <br/> Requested 24 Feb 2020 by Andrea De Cervo and received 24 Feb 2020 from Else Juul Green") 
```
*must request all records as web download limited to max 10000 records per layer*

<br/>

**SMHI Secchi Depth Data**  
<!-- dataset save location BHI_share/BHI 2.0/Goals/CW/EUT/SecchiDepth_SMHI -->
```{r echo = FALSE, results = "asis"}
tab <- t(data.frame(
  c("Datatype:", "Physical and Chemical"), 
  c("Parameter:", "secchi depth"),
  c("Months:", "All"),
  c("Years:", "1893-2020"),
  c("Decimal/fält-avgränsare (decimal/delimiter):", "punkt/semikolon (period/semicolon)"),
  c("Teckenkodning:", "UTF-8"),
  c("Rubrikrad:", "Englelska (English)")))

colnames(tab) <- c("Option", "Specification")
rownames(tab) <- NULL

knitr::kable(tab, caption = "Source: [SMHI Shark database](http://www.smhi.se/klimatdata/oceanografi/havsmiljodata/marina-miljoovervakningsdata) (https://sharkweb.smhi.se) <br/> Downloaded 6 March 2020 by Andrea De Cervo")
```

<br/>

#### 2.1.2 Oxygen Debt {-}

**ICES Oxygen Data**

Each dataset has been extracted by country and Denmark split into five (5) due to large file size.

<!-- dataset save location BHI_share/BHI 2.0/Goals/CW/EUT/OxygenDebt_ICES -->
```{r echo = FALSE, results = "asis"}
tab <- t(data.frame(
  c("Period:", "2000-2020"), 
  c("Parameter:", "Oxygen"),
  c("Country:", "(choose each Baltic country at a time)"),
  c("Ship:", "Any")
))
colnames(tab) <- c("Option", "Specification")
rownames(tab) <- NULL

knitr::kable(tab, caption = "Source: [ICES database](https://ocean.ices.dk/HydChem/HydChem.aspx?plot=yes) <br/> Downloaded 30 March 2020 by Andrea De Cervo. Note: the maximum number of stations per download is 20000.")
```

<br/>

**ICES CTD Data**

Each dataset has been extracted by country, Denmark split into three (3) and Germany into five (5) due to large file size. No CTD records found for Lithuania.

<!-- dataset save location BHI_share/BHI 2.0/Goals/CW/EUT/OxygenDebt_ICES -->
```{r echo = FALSE, results = "asis"}
tab <- t(data.frame(
  c("Period:", "2000-2020"), 
  c("Parameter:", "CTD"),
  c("Country:", "(choose each Baltic country at a time)"),
  c("Ship:", "Any")
))
colnames(tab) <- c("Option", "Specification")
rownames(tab) <- NULL

knitr::kable(tab, caption = "Source: [ICES database](https://ocean.ices.dk/HydChem/HydChem.aspx?plot=yes) <br/> Downloaded 10 April 2020 by Andrea De Cervo. Note: the maximum number of stations per download is 20000.")
```

<br/>

**ICES Hydrogen Sulphide**
<!-- dataset save location BHI_share/BHI 2.0/Goals/CW/EUT/OxygenDebt_ICES -->
```{r echo = FALSE, results = "asis"}
tab <- t(data.frame(
  c("Period:", "2000-2020"), 
  c("Parameter:", "Hydrogen Sulphide"),
  c("Country:", "(choose each Baltic country at a time)"),
  c("Ship:", "Any")
))
colnames(tab) <- c("Option", "Specification")
rownames(tab) <- NULL

knitr::kable(tab, caption = "Source: [ICES database](https://ocean.ices.dk/HydChem/HydChem.aspx?plot=yes) <br/> Downloaded 10 April 2020 by Andrea De Cervo. Note: the maximum number of stations per download is 20000.")
```

<br/>

**SMHI CTD Data**
<!-- dataset save location BHI_share/BHI 2.0/Goals/CW/EUT/OxygenDebt_ICES -->
```{r echo = FALSE, results = "asis"}
tab <- t(data.frame(
  c("Datatype:", "Physical and Chemical"), 
  c("Parameter:", "Dissolved oxygen O2 CTD"),
  c("Months:", "All"),
  c("Years:", "2000-2020"),
  c("Decimal/fält-avgränsare (decimal/delimiter):", "punkt/semikolon (period/semicolon)"),
  c("Teckenkodning:", "UTF-8"),
  c("Rubrikrad:", "Englelska (English)")
))
colnames(tab) <- c("Option", "Specification")
rownames(tab) <- NULL

knitr::kable(tab, caption = "Source: [SMHI database](https://sharkweb.smhi.se/) <br/> Downloaded 16 April 2020 by Andrea De Cervo")
```

<br/>

#### 2.1.3 Chlorophyll a, and Nutrients (DIN and DIP) {-}

**Baltic Nest Datasets**
<!-- dataset save location BHI_share/BHI 2.0/Goals/CW/EUT/NestData/nestdata_winter_nutrients.csv -->
<!-- dataset save location BHI_share/BHI 2.0/Goals/CW/EUT/NestData/nestdata_summer_chlorophyl.csv -->
```{r echo = FALSE, results = "asis"}
tab <- t(data.frame(
  c("Latitude/Longitude Begin/End:", "Baltic Sea"), 
  c("Dates Begin/End:", "Jan 1, 2005 to Dec 31, 2019"), 
  c("Parameters:", "PO4P, NO3N, NO2N, NO23N, NH4N, CHL")
))
colnames(tab) <- c("Option", "Specification")
rownames(tab) <- NULL

knitr::kable(tab, caption = "Source: [Baltic Nest database](http://nest.su.se/dataPortal/getStations) <br/> Downloaded 28 February 2020 by Ellie Campbell. See data.R/get_nest_data function for more detailed info. [About units](http://nest.su.se/bed/chem_struct.shtml).")
```

```{r using get_nest_data function to download winter nutrient data, echo = TRUE, eval = FALSE}
## Retrieving Baltic Nest Nutrients datasets:
get_nest_data(
  date_range = c(20050101,20191231), 
  months = c(11,12,1:3), 
  param_codes = c("NO3N","NO2N","NO23N","NH4N","TOTN","PO4P")
) %>% readr::write_csv(file.path(dir_B, "Goals", "CW", "EUT", "NestData", "nestdata_winter_nutrients.csv"))
```

```{r using get_nest_data function to download summer chlorophyll a data, echo = TRUE, eval = FALSE}
## Retrieve Baltic Nest Chlorophyll a datasets:
get_nest_data(
  date_range = c(20050101, 20191231), 
  months = 5:10, 
  param_codes = c("CHL")
) %>% readr::write_csv(file.path(dir_B, "Goals", "CW", "EUT", "NestData", "nestdata_summer_chlorophyl.csv"))
```
<br/>

**Chlorophyll a Data from SMHI**
<!-- dataset save location BHI_share/BHI 2.0/Goals/CW/EUT/OxygenDebt_ICES -->
```{r echo = FALSE, results = "asis"}
tab <- t(data.frame(
  c("Datatype:", "Physical and Chemical"), 
  c("Parameter:", "Chlorophyll-a bottle"),
  c("Months:", "All"),
  c("Years:", "2000-2020"),
  c("Decimal/fält-avgränsare (decimal/delimiter):", "punkt/semikolon (period/semicolon)"),
  c("Teckenkodning:", "UTF-8"),
  c("Rubrikrad:", "Engelska (English)")))

colnames(tab) <- c("Option", "Specification")
rownames(tab) <- NULL

knitr::kable(tab, caption = "Source: [SMHI Shark database](http://www.smhi.se/klimatdata/oceanografi/havsmiljodata/marina-miljoovervakningsdata) (https://sharkweb.smhi.se) <br/> Downloaded 24 April 2020 by Andrea De Cervo")
```
<br/>

**Chlorophyll a Data from ICES**
<!-- dataset save location BHI_share/BHI 2.0/Goals/CW/EUT/Chla_ICES -->
```{r echo = FALSE, results = "asis"}
tab <- t(data.frame(
  c("Period:", "2000-2020"), 
  c("Parameter:", "Chlorophyll.a"),
  c("Country:", "(choose each Baltic country at a time)"),
  c("Ship:", "Any")))

colnames(tab) <- c("Option", "Specification")
rownames(tab) <- NULL

knitr::kable(tab, caption = "Source: [ICES database](https://ocean.ices.dk/HydChem/HydChem.aspx?plot=yes) <br/> Downloaded 30 April 2020 by Andrea De Cervo. Note: the maximum number of stations per download is 20000")
```

<br/>

#### 2.1.4 HELCOM HOLAS Sub-basins {-}

**HELCOM HOLAS Sub-basins**

These sub-basins are the relevant physical units for the analyses.  

Secchi data will be first assessed at the level of HELCOM subbasin and then assigned to specific BHI regions. The dataset `HELCOM Subbasins with coastal and offshore division 2018` will be used for Secchi as well as Chlorophyll a, DIN and DIP, to assign 'coastal' and 'offshore' locations.

```{r echo = FALSE, results = "asis"}
tab <- t(data.frame(
  c("HELCOM Map and Data service:", "Monitoring"), 
  c("Assessment units:", "HELCOM Subbasins with coastal and offshore division 2018")
))
colnames(tab) <- c("Option", "Specification")
rownames(tab) <- NULL

knitr::kable(tab, caption = "Source: [HELCOM](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/e5a59af9-c244-4069-9752-be3acc5dabed) <br/> Downloaded 23 April 2020 by Andrea De Cervo")
```

<br/>

**HELCOM HOLAS Sub-basins with Coastal WFD Water Bodies**

In addition to this, the dataset `HELCOM subbasins with coastal WFD water bodies or water types 2018` will be used for Chlorophyll a, to assign 'coastal' locations.

```{r echo = FALSE, results = "asis"}
tab <- t(data.frame(
  c("HELCOM Map and Data service:", "Monitoring"), 
  c("Assessment units:", "HELCOM subbasins with coastal WFD water bodies or water types 2018")
))
colnames(tab) <- c("Option", "Specification")
rownames(tab) <- NULL

knitr::kable(tab, caption = "Source: [HELCOM](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/67d653b1-aad1-4af4-920e-0683af3c4a48) <br/> Downloaded 8 June 2020 by Andrea De Cervo")
```

<br/>

#### 2.1.5 Reference Values {-}

**Offshore reference values**

The threshold values have been agreed on by HELCOM and by Heads of Delegation (HOD) and the applied threshold values for core and pre-core indicators in the HELCOM open sea assessment units are presented in the [Baltic Sea Environment Proceedings no.156](http://stateofthebalticsea.helcom.fi/wp-content/uploads/2019/09/BSEP156-Eutrophication.pdf) (p.10, Table 2).

```{r review reference points dataframe, message = FALSE, warning = FALSE, echo = TRUE, results = "hide"}
## eutrophication thresholds data
## Note: this table exists in its original form on the bhi internal shared server 
## read.delim(file.path(dir_rawdata, "eut_threshold_values.csv"), sep = ";")
## obtained originally from (?)
## with columns:  
## basin = str_trim(str_replace_all(Assessment.units,"_",""), side = "right"),
## oxyg_debt = as.numeric(str_replace(O2..mg.l.1., "N", " ")),
## winter_DIN = DIN.._mol.l.1., winter_DIP = DIP.._mol.l.1.,
## summer_chla = Chla.._g.l.1., summer_secchi = Water.clarity..m. 

eut_thresholds <- read_csv(file.path(dir_prep, "prep", "CW", "eutrophication", "eut_threshold_values.csv"))
```
<br/>

**Coastal Chlorophyll a Reference Values**

The coastal threshold values for Chlorophyll a are presented in the [HELCOM Chlorophyll a core indicator](https://helcom.fi/media/core%20indicators/Chlorophyll-a-HELCOM-core-indicator-2018.pdf) (p.5-10, Results Table 2).

```{r review coastal Chl a reference points dataframe, message = FALSE, warning = FALSE, echo = TRUE, results = "hide"}
chla_coastal_thresholds <- read_csv(file.path(dir_rawdata, "chla_coastal_thresholds.csv"))
```
<br/>


**2.1.5.3 Coastal DIN Reference Values**

The coastal threshold values for DIN are presented in the [HELCOM DIN core indicator](https://helcom.fi/media/core%20indicators/Dissolved-inorganic-nitrogen-DIN-HELCOM-core-indicator-2018.pdf) (p.7-8, Results Table 2).

```{r review coastal DIN reference points dataframe, message = FALSE, warning = FALSE, echo = TRUE, results = "hide"}
din_coastal_thresholds <- read_csv(file.path(dir_rawdata, "din_coastal_thresholds.csv"))
```
<br/>


**Coastal DIP Reference Values**

The coastal threshold values for DIP are presented in the [HELCOM DIP core indicator](https://helcom.fi/media/core%20indicators/Dissolved-inorganic-phosphorus-DIP-HELCOM-core-indicator-2018.pdf) (p.6-7, Results Table 2).

```{r review coastal DIP reference points dataframe, message = FALSE, warning = FALSE, echo = TRUE, results = "hide"}
dip_coastal_thresholds <- read_csv(file.path(dir_rawdata, "dip_coastal_thresholds.csv"))
```

<br/>

### 2.2 Centralization & Normalization {-}

#### 2.2.1 Secchi Datasets {-}

```{r read raw secchi datasets, message = FALSE, warning = FALSE, echo = TRUE, results = "hide"}
## read in secchi data
secchi_raw_ices <- read.delim(
  file.path(dir_rawdata, "SecchiDepth_ICES", "SecchiDepth_ICES.csv"), 
  sep = ";",
  stringsAsFactors = FALSE
)
secchi_raw_smhi <- read.delim(
  file.path(dir_rawdata, "SecchiDepth_SMHI", "SecchiDepth_SMHI.csv"), 
  sep = ";",
  stringsAsFactors = FALSE
)
basin_add_lookup_table <- read.csv(file.path(dir_prep, "supplement", "lookup_tabs", "basin_add_lookup_table.csv"))
```

**Coastal data**  

- Non-coastal (offshore) data are flagged with the code "0" under the column *"HELCOM_COASTAL_CODE"*  
- HELCOM basin shape files with coastal and non-coastal areas were overlaid with the secchi sampling locations, all locations were flagged with a code indicating coastal or offshore.  
- Coastal data are later removed from the analysis  

**Steps in Merging ICES and SMHI Secchi Datasets**

1) Rename variables and subset datasets to be merged, so column names and data types align
2) Check duplicates and select only distinct observations
3) Combine SMHI and ICES data, identifying and eliminating overlaps

```{r cleaning secchi ices raw data, echo = TRUE, results = "hide", eval = FALSE}
## ICES Secchi Data

## overview
# colnames(secchi_raw_ices)
# str(secchi_raw_ices)

## Merge the add basin lookup table to ices dataset
ices_secchi <- secchi_raw_ices %>% 
  rename(
    secchi = Secchi.Depth..m.,
    latitude = Latitude..degrees_north.,
    longitude = Longitude..degrees_east., 
    bottom_m = Bot..Depth..m.
  ) %>%
  mutate(
    date =  as.Date(yyyy.mm.ddThh.mm), 
    year = format(date, "%Y"), 
    month = format(date, "%m"),
    month = str_replace(month, "^0+", ""),
    cruise = as.character(Cruise),
    station = as.character(Station),
    bottom_m = as.numeric(bottom_m)
  ) %>%
  select(-Type, -yyyy.mm.ddThh.mm) 

## Look for Duplicates in the Data:
## check for duplicates in ices
ices_duplicates <- ices_secchi %>%
  group_by(
    cruise, station, date, year, month, 
    latitude, longitude, 
    secchi, bottom_m
  ) %>%
  summarise(n = n()) %>%
  filter(n > 1) %>%
  ungroup() 

## Only extract unique observations
secchi_ices_unique <- ices_secchi %>% 
  distinct(
    cruise, station, date, year, month, 
    latitude, longitude, 
    secchi, bottom_m
  ) %>% 
  ## removed 'Assessment_unit'
  mutate(supplier = "ices") # nrow(ices_unique) 102881
```

```{r cleaning smhi secchi raw data, echo = TRUE, results = "hide"}
## SMHI Secchi Data 

## overview
# colnames(secchi_raw_smhi)
# str(secchi_raw_smhi)

## ADJUST ROWS
## three extra columns starting with 'X' indicate some weird column shifts

## correct where Sample depths columns have been shifted one or two columns over 
depth_measurement <- "^[0-9]{0,3}\\.[0-9]+$|^[0-9]{1,3}$"
fix_data_smhi <- secchi_raw_smhi %>% 
  filter(!str_detect(Sample.minimum.depth, depth_measurement)) %>% 
  mutate(Sample.maximum.depth = as.character(Sample.maximum.depth)) %>%
  mutate(Sampling.laboratory = as.numeric(as.character(Sampling.laboratory))) %>%
  select(-Sample.minimum.depth)
colnames(fix_data_smhi) <- setdiff(colnames(secchi_raw_smhi), "Sample.comment")

## bind corrected rows back to the other rows
secchi_smhi_correctcols <- secchi_raw_smhi %>% 
  filter(str_detect(Sample.minimum.depth, depth_measurement)) %>% 
  bind_rows(mutate(fix_data_smhi, Sample.comment = NA))

fix_data_smhi <- secchi_smhi_correctcols %>% 
  filter(is.na(Sample.minimum.depth), str_detect(Sampling.laboratory, depth_measurement)) %>% 
  mutate(Sample.maximum.depth = as.character(Sample.maximum.depth)) %>%
  mutate(Sampling.laboratory = as.numeric(as.character(Sampling.laboratory))) %>%
  select(-Sample.minimum.depth)
colnames(fix_data_smhi) <- setdiff(colnames(secchi_smhi_correctcols), "Species.flag")
secchi_smhi_correctcols <- secchi_smhi_correctcols %>% 
  filter(!(is.na(Sample.minimum.depth) & str_detect(Sampling.laboratory, depth_measurement))) %>% 
  bind_rows(mutate(fix_data_smhi, Species.flag = NA))

## rows where parameter, values, and units are shifted
## cols to right of parameter column are shifted one or two to the right
fix_data_smhi <- secchi_smhi_correctcols %>%
  filter(str_detect(Value, "Secchi depth")) %>%
  select(-Parameter)
colnames(fix_data_smhi) <- setdiff(colnames(secchi_smhi_correctcols), "Data.set.name")
secchi_smhi_correctcols <- bind_rows(
  mutate(fix_data_smhi, Data.set.name = NA),
  filter(secchi_smhi_correctcols, !str_detect(Value, "Secchi depth"))
)
fix_data_smhi <- secchi_smhi_correctcols %>%
  filter(str_detect(Unit, "Secchi depth")) %>%
  select(-Parameter, -Value)
colnames(fix_data_smhi) <- setdiff(colnames(secchi_smhi_correctcols), c("File.name",  "Data.set.name"))
secchi_smhi_correctcols <- bind_rows(
  mutate(fix_data_smhi, File.name = NA, Data.set.name = NA),
  filter(secchi_smhi_correctcols, !str_detect(Unit, "Secchi depth"))
)

## check result of column shift corrections
# dim(secchi_raw_smhi)
# dim(secchi_smhi_correctcols)
# for(col in c("Sample.minimum.depth", "Sample.maximum.depth", "Parameter", "Unit")){
#   print(unique(secchi_smhi_correctcols[[col]]))
# }
# summary(as.numeric(unique(secchi_smhi_correctcols[["Value"]])))
# dim(filter(secchi_smhi_correctcols, Parameter != "Secchi depth"))


secchi_smhi <- secchi_smhi_correctcols %>% 
  filter(Parameter == "Secchi depth") %>% 
  mutate(
    Value = as.numeric(as.character(Value)), 
    Parameter = as.character(Parameter)
  ) %>% 
  rename(
    secchi = Value, 
    date = Sampling.date, 
    cruise = Visit.event.identifier, 
    station = Station.name, 
    ## use the decimal degrees for lat and lon
    latitude = Sample.latitude..DD., 
    longitude = Sample.longitude..DD.,
    ## 'Station.water.depth' or 'Sample.maximum.depth' cosidered as 'Bottom depth'?
    bottom_m = Station.water.depth # Sample.maximum.depth??
  ) %>% 
  mutate(
    date = as.Date(date), 
    year = as.character(format(date, "%Y")),
    month = format(date, "%m"),
    month = str_replace(month, "^0+" ,""),
    bottom_m = as.numeric(bottom_m),
    station = as.character(station),
    cruise = as.character(cruise)
  ) %>% 
  select(cruise, station, date, year, month, latitude, longitude, secchi, bottom_m) 

## Look for duplicate data points
secchi_smhi_duplicates <- secchi_smhi %>%
  group_by(
    cruise, station, date, year, month, 
    latitude, longitude, 
    secchi, bottom_m
  ) %>%
  summarise(n = n()) %>%
  filter(n > 1) %>%
  ungroup()
# sum(secchi_smhi_duplicates$n)-nrow(secchi_smhi_duplicates)

## extract only unique observations
secchi_smhi_unique <- secchi_smhi %>% 
  distinct(
    cruise, station, date, year, month, 
    latitude, longitude, 
    secchi, bottom_m
  ) %>% 
  mutate(supplier = "smhi") 
# nrow(secchi_smhi)-nrow(secchi_smhi_unique)
```

```{r combine all secchi datasets, echo = TRUE, results = "hide", eval = FALSE}
## Combined Secchi Data

merge_secchi_datasets <- bind_rows(secchi_smhi_unique, secchi_ices_unique) %>% 
  ## prefer first ices, then smhi data where there are overlaps
  mutate(supplier_num = ifelse(supplier == "ices", 2, 1)) %>% 
  group_by(date, year, month, latitude, longitude, secchi, bottom_m) %>% 
  top_n(n = 1)

# summary(as.factor(merge_secchi_datasets$supplier))
# tmp <- merge_secchi_datasets %>%
#   group_by(cruise, station, date, year, month, latitude, longitude, secchi, bottom_m) %>%
#   mutate(count = n())
# unique(tmp$count)

secchi <- rename(merge_secchi_datasets, lat = latitude, lon = longitude, secchi_m = secchi)
# nrow(distinct(secchi))

## Save merged dataset
# readr::write_csv(
#   secchi,
#   here::here("data", "CW", "eutrophication", version_year, "intermediate", "secchi_merged_rawdata.csv")
# )
```
<br/>

#### 2.2.2 Merging Oxygen Datasets {-}

```{r function to read raw oxygen datasets, message = FALSE, warning = FALSE, echo = TRUE, results = "hide"}
## this will read in both the oxygen and CTD datasets from the OxygenDebt_ICES directory
## in the same step, this will check for duplicates and then keep only the distinct observations
read_ox_data <- function(datasets = "ox"){
  
  lapply(
    ## lists all subfiles in OxygenDebt_ICES directory, and selects only ones with csv extension
    grep(
      pattern = datasets, 
      list.files(file.path(dir_rawdata, "OxygenDebt_ICES"), pattern = ".csv", recursive = TRUE),
      value = TRUE
    ),
    ## read in the file and assign to a variable in the global environment
    function(x){
      tmp <- read.delim(file.path(dir_rawdata, "OxygenDebt_ICES", x), sep = ",", stringsAsFactors = FALSE)
      
      ## Check for duplicates in all national datasets
      # duplicates <- tmp %>% 
      #   group_by(
      #     Cruise, Station, yyyy.mm.ddThh.mm, Bot..Depth..m., TEMP..deg.C., PSAL..psu.,
      #     PRES..db., Latitude..degrees_north., Longitude..degrees_east., DOXY..ml.l.
      #   ) %>%
      #   summarise(n = n()) %>%
      #   filter(n > 1) %>%
      #   ungroup()
      
      ## Extract only unique observations
      uniquedat <- tmp %>% 
        distinct(
          Cruise, Station, yyyy.mm.ddThh.mm, Bot..Depth..m., TEMP..deg.C., PSAL..psu.,
          PRES..db., Latitude..degrees_north., Longitude..degrees_east., DOXY..ml.l.
        )
      nam <- x %>% 
        stringr::str_extract("[a-zA-Z_0-9\\-]+.csv|[a-z0-9\\-]+.csv|[a-z]+.csv") %>% 
        stringr::str_remove_all(".csv") %>% 
        stringr::str_remove_all("[0-9]{4}\\-[0-9]{2}")
      ## different ctd and h2s naming conventions...
      nam <- ifelse(nam == "0410032c", "finlandctd", nam)
      nam <- ifelse(str_detect(nam, "CTD_"), paste0(str_remove(nam, "CTD_"), "ctd"), nam)
      nam <- ifelse(str_detect(nam, "H2S_"), paste0(str_remove(nam, "H2S_"), "h2s"), nam)
      
      ## assign to names in global environment...
      if(str_detect(nam, "ox$")){
        assign(sprintf("ox_%s", nam), uniquedat, envir = .GlobalEnv)
      }
      if(str_detect(nam, "ctd$")){
        assign(sprintf("ctd_%s", nam), uniquedat, envir = .GlobalEnv)
      }
      if(str_detect(nam, "h2s$")){
        assign(sprintf("h2s_%s", nam), uniquedat, envir = .GlobalEnv)
      }
    }
  ) 
}
```
<br/>

```{r merge country oxygen data and all CTD country data to make 2 df with rgn info, eval = FALSE}
## Merging oxygen datasets, only unique entries
read_ox_data(datasets = "ox")
oxdata_to_merge <- ls(pattern = "ox_[a-z].*ox$")

ox_merged <- do.call(rbind, lapply(oxdata_to_merge, function(x){
  cbind(get(x), Country = stringr::str_remove_all(x, "ox|_|[0-9]"))
})) 
ox_merged <- ox_merged %>%
  rename(
    Oxygen = DOXY..ml.l.,
    Date = yyyy.mm.ddThh.mm, 
    Latitude = Latitude..degrees_north.,
    Longitude = Longitude..degrees_east., 
    Temperature = TEMP..deg.C., 
    Salinity = PSAL..psu., 
    Depth = PRES..db., # what is this, pressure or depth?
    Bot_Depth = Bot..Depth..m. # so many NAs in this variable....
  ) %>%
  mutate(
    Year = as.numeric(format(strptime(Date, "%Y-%m-%dT%H:%M"), "%Y")),
    Month = as.numeric(format(strptime(Date, "%Y-%m-%dT%H:%M"), "%m")),
    Day = as.numeric(format(strptime(Date, "%Y-%m-%dT%H:%M"), "%d")),
    Hour = as.numeric(format(strptime(Date, "%Y-%m-%dT%H:%M"), "%H")),
    Minute = as.numeric(format(strptime(Date, "%Y-%m-%dT%H:%M"), "%M")),
    Date = as.Date(Date, "%Y-%m-%d"),
    Station = as.character(Station),
    Oxygen_Original = as.character(Oxygen),
    Oxygen = as.numeric(Oxygen_Original),
    Depth = as.numeric(Depth)
  )
## in some cases oxygen data has non-numeric characters, <0.01 for example...
## these become NAs when coerced to numeric
## what is the best approach: give value of 0.01, NA, or zero?
ox_merged_w_rgns <- join_rgns_info(
  dataset = ox_merged,
  rgn_shps_loc = file.path(dirname(dir_B), "Shapefiles")
)

colnames(ox_merged_w_rgns) <- str_to_title(names(ox_merged_w_rgns))
ox_merged_w_rgns <- ox_merged_w_rgns %>% 
  filter(!is.na(Helcom_id), !is.na(Oxygen)) %>% 
  select(-Ices_area, -In_25km_buffer, -Rgn_nam, -Rgn_key, -Oxygen_original, -Date) %>%
  rename(Bot_Depth = Bot_depth, BHI_ID = Bhi_id, Assessment_Unit = Helcom_id)

## CTD datasets
read_ox_data(datasets = "CTD/")
ctd_data_to_merge <- ls(pattern = "ctd_[a-z].*ctd$")
## issue with sweden dataset, no oxygen column...
ctd_data_to_merge <- setdiff(ctd_data_to_merge, "ctd_sweden20ctd")

ctd_merged <- do.call(rbind, lapply(ctd_data_to_merge, function(x){
  cbind(get(x), Country = stringr::str_remove_all(x, "ctd|_|[0-9]"))
})) 
ctd_merged <- ctd_merged %>%
  rename(
    Oxygen = DOXY..ml.l.,
    Date = yyyy.mm.ddThh.mm,
    Latitude = Latitude..degrees_north.,
    Longitude = Longitude..degrees_east.,
    Temperature = TEMP..deg.C.,
    Salinity = PSAL..psu.,
    Depth = PRES..db., # what is this, pressure or depth?
    Bot_Depth = Bot..Depth..m. # so many NAs in this variable....
  ) %>%
  mutate(
    Year = as.numeric(format(strptime(Date, "%Y-%m-%dT%H:%M"), "%Y")),
    Month = as.numeric(format(strptime(Date, "%Y-%m-%dT%H:%M"), "%m")),
    Day = as.numeric(format(strptime(Date, "%Y-%m-%dT%H:%M"), "%d")),
    Hour = as.numeric(format(strptime(Date, "%Y-%m-%dT%H:%M"), "%H")),
    Minute = as.numeric(format(strptime(Date, "%Y-%m-%dT%H:%M"), "%M")),
    Date = as.Date(Date, "%Y-%m-%d"),
    Station = as.character(Station),
    Oxygen_Original = as.character(Oxygen),
    Oxygen = as.numeric(Oxygen_Original),
    Depth = as.numeric(Depth)
  )
rm(ctd_data_to_merge)

ctd_merged_w_rgns <- join_rgns_info(
  dataset = ctd_merged,
  rgn_shps_loc = file.path(dirname(dir_B), "Shapefiles")
)

colnames(ctd_merged_w_rgns) <- str_to_title(names(ctd_merged_w_rgns))

ctd_merged_w_rgns <- ctd_merged_w_rgns %>%
  filter(!is.na(Helcom_id), !is.na(Oxygen)) %>% 
  select(-Ices_area, -In_25km_buffer, -Rgn_nam, -Rgn_key, -Oxygen_original, -Date) %>%
  rename(Bot_Depth = Bot_depth, BHI_ID = Bhi_id, Assessment_Unit = Helcom_id)
```

```{r save ctd and bottle oxygen datasets, eval = FALSE}
## Save datasets
dir_interm <- here::here("data", "CW", "eutrophication", version_year, "intermediate")

## maybe in future look into using for big files: 
## https://docs.ropensci.org/piggyback/
readr::write_csv(
  select(ox_merged_w_rgns, -BHI_ID, -Country, -Subbasin, -Station, -Bot_Depth),
  file.path(dir_interm, "ox_merged_rawdata.csv")
)
readr::write_csv(
  select(ctd_merged_w_rgns, -BHI_ID, -Country, -Subbasin, -Station, -Bot_Depth),
  file.path(dir_interm, "ctd_merged_rawdata.csv")
)
```

#### 2.2.3 Chlorophyll a Wrangling

```{r read raw smhi and nest chla datasets, message = FALSE, warning = FALSE, echo = TRUE, results = "hide"}
chla_raw_nest <- read.delim(file.path(dir_rawdata, "NestData", "nestdata_summer_chlorophyl.csv"), sep = ",")
chla_raw_smhi <- read.delim(file.path(dir_rawdata, "chla_rawdata_smhi.csv"), sep = ";")
```

**Coastal data**  

- Non-coastal (offshore) data are flagged with the code "0" under the column *"HELCOM_COASTAL_CODE"*  
- HELCOM basin shape files with coastal and non-coastal areas were overlaid with the Chl _a_ sampling locations, all locations were flagged with a code indicating coastal or offshore. 

**Steps in Merging ICES and SMHI Secchi Datasets**

1) Rename variables and subset datasets to be merged, so column names and data types align
2) Check duplicates and select only distinct observations
3) Combine Baltic Nest, SMHI and ICES data, identifying and eliminating overlaps

```{r cleaning chla nest raw data, results = "hide", message = FALSE, echo = TRUE}
## Baltic Nest Chlorophyll a Data

chla_nest <- chla_raw_nest %>% 
  rename(
    chla_ug_l = CHL,  
    date = OBSDATE, time = OBSTIME,
    latitude = LATITUDE, longitude = LONGITUDE, 
    cruise = SHIP, id = ID, depth_m = OBSDEP
  ) %>%
  mutate(
    date = as.Date(date), 
    year = format(date, "%Y"), 
    month = format(date, "%m"),
    cruise = as.character(cruise)
  ) %>% 
  select(-id, -time)

## Check for duplicates 
chla_nest_duplicates <- chla_nest %>%
  group_by(
    cruise, date, year, month, 
    latitude, longitude, 
    chla_ug_l, depth_m
  ) %>%
  summarise(n = n()) %>%
  filter(n > 1) %>%
  ungroup()
# sum(chla_nest_duplicates$n)-nrow(chla_nest_duplicates)

## Only extract unique observations
chla_nest_unique <- chla_nest %>% 
  distinct(
    cruise, date, year, month, 
    latitude, longitude, 
    chla_ug_l, depth_m
  ) %>% 
  mutate(supplier = "nest") # 44071
# nrow(chla_nest)-nrow(chla_nest_unique)
```

```{r cleaning chla smhi raw data, message = FALSE, warning = FALSE, echo = TRUE, results = "hide"}
## SMHI Chlorophyll a Data

## overview
# colnames(chla_raw_smhi)
# str(chla_raw_smhi)

## ADJUST ROWS
## three extra columns starting with 'X' indicate some weird column shifts

## correct where Sample depths columns have been shifted one or two columns over 
depth_measurement <- "^[0-9]{0,3}\\.[0-9]+$|^[0-9]{1,3}$"
fix_data_smhi <- chla_raw_smhi %>% 
  filter(!str_detect(Sample.minimum.depth, depth_measurement)) %>% 
  mutate(Sample.maximum.depth = as.character(Sample.maximum.depth)) %>%
  mutate(Sampling.laboratory = as.numeric(as.character(Sampling.laboratory))) %>%
  select(-Sample.minimum.depth)
colnames(fix_data_smhi) <- setdiff(colnames(chla_raw_smhi), "Sample.comment")

## bind corrected rows back to the other rows
chla_smhi_correctcols <- bind_rows(
  mutate(fix_data_smhi, Sample.comment = NA),
  filter(chla_raw_smhi, str_detect(Sample.minimum.depth, depth_measurement))
)

fix_data_smhi <- chla_smhi_correctcols %>% 
  filter(is.na(Sample.minimum.depth), str_detect(Sampling.laboratory, depth_measurement)) %>% 
  mutate(Sample.maximum.depth = as.character(Sample.maximum.depth)) %>% 
  mutate(Sampling.laboratory = as.numeric(as.character(Sampling.laboratory))) %>% 
  select(-Sample.minimum.depth)
colnames(fix_data_smhi) <- setdiff(colnames(chla_smhi_correctcols), "X.3")
chla_smhi_correctcols <- bind_rows(
  mutate(fix_data_smhi, X.3 = NA),
  filter(chla_smhi_correctcols, !(is.na(Sample.minimum.depth) & str_detect(Sampling.laboratory, depth_measurement)))
)

## rows where parameter and values are shifted
## cols to right of parameter column are shifted one or two to the right
fix_data_smhi <- chla_smhi_correctcols %>% 
  filter(str_detect(Value, "Chlorophyll-a bottle")) %>% 
  select(-Parameter)
colnames(fix_data_smhi) <- setdiff(colnames(chla_smhi_correctcols), "X.3")
chla_smhi_correctcols <- bind_rows(
  mutate(fix_data_smhi, X.3 = NA),
  filter(chla_smhi_correctcols, !str_detect(Value, "Chlorophyll-a bottle"))
)
fix_data_smhi <- chla_smhi_correctcols %>% 
  filter(str_detect(Unit, "Chlorophyll-a bottle")) %>% 
  select(-Parameter, -Value)
colnames(fix_data_smhi) <- setdiff(colnames(chla_smhi_correctcols), c("X.2","X.3"))
chla_smhi_correctcols <- bind_rows(
  mutate(fix_data_smhi, X.2 = NA, X.3 = NA),
  filter(chla_smhi_correctcols, !str_detect(Unit, "Chlorophyll-a bottle"))
)

## check result of column shift corrections
# for(col in c("Sample.minimum.depth", "Sample.maximum.depth", "Parameter", "Unit")){
#   print(unique(chla_smhi_correctcols[[col]]))
# }
# summary(as.numeric(unique(chla_smhi_correctcols[["Value"]])))
# dim(filter(chla_smhi_correctcols, Parameter != "Chlorophyll-a bottle"))


chla_smhi <- chla_smhi_correctcols %>% 
  filter(Parameter == "Chlorophyll-a bottle") %>% 
  mutate(
    Value = as.numeric(as.character(Value)), 
    Parameter = as.character(Parameter)
  ) %>% 
  rename(
    chla_ug_l = Value, 
    date = Sampling.date, 
    cruise = Visit.event.identifier, 
    station = Station.name, 
    ## use the decimal degrees for lat and lon
    latitude = Sample.latitude..DD., 
    longitude = Sample.longitude..DD.,
    ## 'Station.water.depth' or 'Sample.maximum.depth' cosidered as 'Bottom depth'?
    depth_m = Sample.maximum.depth
  ) %>% 
  mutate(
    date = as.Date(date), 
    year = as.character(format(date, "%Y")),
    month = format(date, "%m"),
    # month = str_replace(Month, "^0+" ,""),
    depth_m = as.numeric(depth_m),
    # station = as.character(station),
    cruise = as.character(cruise)
  ) %>% 
  select(cruise, date, year, month, latitude, longitude, chla_ug_l, depth_m) 

## Look for duplicate data points
chla_smhi_duplicates <- chla_smhi %>%
  group_by(
    cruise, date, year, month, 
    latitude, longitude, 
    chla_ug_l, depth_m
  ) %>%
  summarise(n = n()) %>%
  filter(n > 1) %>%
  ungroup()
# sum(chla_smhi_duplicates$n)-nrow(chla_smhi_duplicates)

## extract only unique observations
chla_smhi_unique <- chla_smhi %>% 
  distinct(
    cruise, date, year, month, 
    latitude, longitude, 
    chla_ug_l, depth_m
  ) %>% 
  mutate(supplier = "smhi") 
# nrow(chla_smhi)-nrow(chla_smhi_unique)
```

```{r cleaning chla ices raw datasets, message = FALSE, warning = FALSE, echo = TRUE, results = "hide"}
## ICES Chlorophyll a Data


## this will read in the chl a datasets from our Chla_ICES directory and bind them into one
chla_raw_ices <- do.call(rbind, lapply(
  grep(list.files(file.path(dir_rawdata, "Chla_ICES"), recursive = TRUE), pattern = ".csv", value =  TRUE),
  function(x){
    cbind(
      read.delim(file.path(dir_rawdata, "Chla_ICES", x), sep = ","), 
      country = str_extract(x, pattern = "^[a-z]*")
    )
  }
))
chla_ices <- chla_raw_ices %>% 
  select(-Type) %>% 
  rename(
    date = yyyy.mm.ddThh.mm,
    latitude = Latitude..degrees_north.,
    longitude = Longitude..degrees_east.,
    station = Station, 
    cruise = Cruise, 
    temperature = TEMP..deg.C.,
    salinity = PSAL..psu.,
    pressure = PRES..db., 
    chla_ug_l = CPHL..ug.l.,
    depth_m = Bot..Depth..m. # so many NAs in this variable....
  ) %>% 
  mutate(
    year = format(strptime(date, "%Y-%m-%dT%H:%M"), "%Y"),
    month = format(strptime(date, "%Y-%m-%dT%H:%M"), "%m"),
    date = as.Date(date, "%Y-%m-%d"),
    station = as.character(station),
    pressure = as.numeric(pressure),
    depth_m = as.numeric(depth_m),
    chla_ug_l = str_replace(chla_ug_l, "<", ""),
    ## keep the values or set a range lower than that?
    chla_ug_l = as.numeric(chla_ug_l)
  )

## Check for duplicates in ICES secchi data
ices_duplicates <- chla_ices %>%
  group_by(
    cruise, station, latitude, longitude, 
    date, year, month,
    chla_ug_l, depth_m
  ) %>%
  summarize(n = n()) %>%
  filter(n > 1) %>%
  ungroup() 
# sum(ices_duplicates$n)-nrow(ices_duplicates) # 22595

## Extract only unique observations
chla_ices_unique <- chla_ices %>% 
  distinct(
    cruise, station, latitude, longitude, 
    date, year, month,
    chla_ug_l, depth_m
  ) %>% 
  mutate(supplier = "ices") 
# nrow(chla_ices)-nrow(chla_ices_unique) # 22595
```

```{r combine all chla datasets, warning = FALSE, message = FALSE, echo = TRUE, results = "hide"}
## Combined Chlorophyll a Data

merge_chla_datasets <- bind_rows(chla_nest_unique, chla_smhi_unique, chla_ices_unique) %>% 
  filter(chla_ug_l >= 0) %>% 
  ## prefer first ices, then smhi, then nest data where there are overlaps
  mutate(supplier_num = ifelse(supplier == "ices", 3, ifelse(supplier == "smhi", 2, 1))) %>% 
  group_by(date, year, month, latitude, longitude, chla_ug_l, depth_m) %>% 
  top_n(n = 1)

# summary(as.factor(merge_chla_datasets$supplier))
# tmp <- merge_chla_datasets %>%
#   group_by(cruise, station, date, year, month, latitude, longitude, chla_ug_l, depth_m) %>%
#   mutate(count = n())
# unique(tmp$count)
```

```{r save merged chla dataset, eval = FALSE}
chla <- rename(merge_chla_datasets, lat = latitude, lon = longitude)
# nrow(distinct(chla))

## Save merged dataset
readr::write_csv(
  chla,
  here::here("data", "CW", "eutrophication", version_year, "intermediate", "chla_rawdata.csv")
)
```

<br/>

### 2.3 Initial Data Exploration {-}

#### 2.3.1 Maps of SMHI datasets

```{r basemap to be used in spatial plotting, echo = TRUE}
basemap <- ggplot2::ggplot(rnaturalearth::ne_countries(scale = "medium", returnclass = "sf")) +
  geom_sf(size = 0.1, color = "burlywood", alpha = 0.4) +
  theme(panel.background = element_rect(fill = "#F8FBFC", color = "#E2EEF3")) +
  scale_x_continuous(limit = c(4, 32)) +
  scale_y_continuous(limit = c(53.5, 66)) 

## make larger discrete color palette
pal <- colorRampPalette(RColorBrewer::brewer.pal(8, "Set2"))(17)
```

```{r chla raw datasets, results = "show", echo = TRUE, fig.width = 9.5, fig.height = 7}
smhi_secchi_map <- basemap +
  geom_sf(
    mapping = aes(color = Sea.basin), 
    data = sf::st_as_sf(
      filter(secchi_smhi_correctcols, HELCOM.OSPAR.area %in% c("HELCOM", "OSPAR/HELCOM"), str_detect(Sea.basin, "[0-9]")), 
      coords = c("Sample.longitude..DD.", "Sample.latitude..DD."), 
      crs = 4326
    ),
    size = 0.5, alpha = 0.3, show.legend = FALSE
  ) +
  labs(
    color = "Sea Basin", 
    title = "Secchi SMHI Data Measurement Locations"
  ) +
  # theme(legend.position = c(0.2, 0.7)) +
  scale_color_manual(values = pal)

smhi_chla_map <- basemap +
  geom_sf(
    mapping = aes(color = Sea.basin), 
    data = sf::st_as_sf(
      filter(chla_smhi_correctcols, HELCOM.OSPAR.area %in% c("HELCOM", "OSPAR/HELCOM"), str_detect(Sea.basin, "[0-9]")), 
      coords = c("Sample.longitude..DD.", "Sample.latitude..DD."), 
      crs = 4326
    ),
    size = 0.5, alpha = 0.3
  ) +
  labs(
    color = "Sea Basin", 
    title = "Chlorophyll a SMHI Data Measurement Locations"
  ) +
  # theme(legend.position = c(0.2, 0.7)) +
  scale_color_manual(values = pal)

gridExtra::grid.arrange(smhi_secchi_map, smhi_chla_map, nrow = 2, heights = c(1.3, 1))
```
<br>

#### 2.3.2 Oxygen data

In the depth vs dissolved oxygen plots below, the lighter greens and yellow correspond to earlier years, and darker greens and purples represent more recent years.

```{r map showing oxygen datasets, results = "show", message = FALSE, warning = FALSE, echo = TRUE, fig.width = 9.5, fig.height = 6}
dir_interm <- here::here("data", "CW", "eutrophication", version_year, "intermediate")
ox_merged_w_rgns <- readr::read_csv(file.path(dir_interm, "ox_merged_rawdata.csv"))
ctd_merged_w_rgns <- readr::read_csv(file.path(dir_interm, "ctd_merged_rawdata.csv"))

## quick maps of measurements by subbasin for selected year
oxplotsf <- ox_merged_w_rgns %>% 
  filter(Year == 2018, !is.na(Assessment_Unit)) %>% 
  sf::st_as_sf(crs = 4326, coords = c("Longitude", "Latitude"))
oxmap <- basemap + 
  geom_sf(
    data = oxplotsf, 
    aes(color = Assessment_Unit), 
    size = 0.4, alpha = 0.02
  ) +
  ggtitle("Dissolved Oxygen Bottle\nMeasurement Locations") +
  scale_color_manual(values = pal)

ctdplotsf <- ctd_merged_w_rgns %>% 
  filter(Year == 2018) %>% 
  sf::st_as_sf(crs = 4326, coords = c("Longitude", "Latitude"))
ctdmap <- basemap + 
  geom_sf(
    data = ctdplotsf, 
    aes(color = Assessment_Unit), 
    size = 0.4, alpha = 0.02, show.legend = FALSE
  ) +
  ggtitle("Dissolved Oxygen CTD \nMeasurement Locations") +
  scale_color_manual(values = pal)

## plot by subbasins
oxplotdf <- ox_merged_w_rgns %>% 
  filter(!is.na(Assessment_Unit)) %>% 
  group_by(Assessment_Unit) %>%
  sample_n(3000) %>%
  mutate(Date = as.Date(paste(Year, Month, Day, sep = "-")))
ctdplotdf <- ctd_merged_w_rgns %>% 
  filter(!is.na(Assessment_Unit)) %>% 
  group_by(Assessment_Unit) %>%
  sample_n(2000) %>%
  mutate(Date = as.Date(paste(Year, Month, Day, sep = "-")))

oxplot <- ggplot(oxplotdf, aes(Oxygen, Depth, color = Year)) + 
  geom_point(alpha = 0.02, size = 0.7, show.legend = FALSE) +
  facet_wrap(~Assessment_Unit, scales = "free_y", ncol = 3)  +
  labs(x = "Dissolved Oxygen (ml/l)", y = "Depth (m)") +
  scale_y_reverse() +
  scale_color_viridis_c(direction = -1)
ctdplot <- ggplot(ctdplotdf, aes(Oxygen, Depth, color = Year)) + 
  geom_point(alpha = 0.02, size = 0.7, show.legend = FALSE) +
  facet_wrap(~Assessment_Unit, scales = "free_y", ncol = 3)  +
  labs(
    x = "Dissolved Oxygen (ml/l)", 
    y = "Depth (m)"
    # caption = paste(
    #   "Dissolved Oxygen (ml/l) vs Sub-basin Depth (m)",
    #   "The lighter greens and yellow correspond to earlier years", 
    #   "and darker greens and purples represent more recent years.",
    #   "Plot on the left shows bottle data, plot on the right shows CTD data."
    # )
  ) + 
  scale_y_reverse() +
  scale_color_viridis_c(direction = -1) +
  theme(plot.caption = element_text(hjust = 0,  size = 6))

## timeseries plot
tsplotdf <- rbind(
  mutate(oxplotdf, measure_type = "Bottle") %>% select(-Bot_Depth, -Station),
  mutate(ctdplotdf, measure_type = "CTD")
)
oxtsplot <- ggplot(tsplotdf, aes(Date, Oxygen, color = measure_type)) + 
  geom_point(size = 0.1, alpha = 0.05, show.legend = FALSE) +
  facet_wrap(~Assessment_Unit, ncol = 3) +
  labs(
    x = "Year", 
    y = "Dissolved Oxygen (ml/l, Bottle data in pink and CTD data in Blue)",
    caption = paste(
      "Timeseries of dissolved oxygen (ml/l) by Sub-basin.",
      "Bottle data are shown in pink and CTD data in blue."
    )
  ) + 
  theme(plot.caption = element_text(hjust = 0))


gridExtra::grid.arrange(oxmap, ctdmap, nrow = 2, widths = c(1.2, 1))

#gridExtra::grid.arrange(
#  oxplot, ctdplot, oxtsplot,
#  layout_matrix = matrix(c(1,2,3,3), ncol = 2, byrow = TRUE)
#)
```

<br>

#### 2.3.3 Comparing chl a data Sources

```{r chlorophyl a data source histograms, results = "show", fig.width = 9.5, fig.height = 6}
plotdf <- filter(merge_chla_datasets, chla_ug_l < 50, year %in% 2000:2019)

ggplot(plotdf %>% mutate(supplier = stringr::str_to_upper(supplier))) + 
  geom_histogram(aes(chla_ug_l, fill = month), alpha = 0.8, bins = 80, size = 0.2) +
  facet_grid(rows = vars(supplier)) +
  labs(x = "Chlorophyll a (ug/L)", y = NULL, fill = "Month") +
  scale_fill_manual(values = pal)+
  theme(legend.position = c(0.95, 0.3))
```


<!-- #### 2.3.1 Compare versus Previous Years Data {-} -->

<!-- #### 2.3.2 Timeseries Plots {-} -->

<!-- #### 2.3.3 Map {-} -->
